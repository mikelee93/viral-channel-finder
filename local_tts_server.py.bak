from flask import Flask, request, send_file
import torch
from transformers import AutoProcessor, AutoModel
# ...

# Config
MODEL_ID = "Qwen/Qwen3-TTS-12Hz-1.7B-CustomVoice"
PORT = 5001

print(f"Loading model: {MODEL_ID}...")
import transformers
print(f"Transformers version: {transformers.__version__}")
print(f"Transformers path: {transformers.__file__}")
try:
    # Using AutoModel with trust_remote_code=True to handle Custom Architecture
    # Logic: SafeTensors + Default Loading is safest on Windows
    print("Loading model with AutoModel (Standard Mode)...")
    model = AutoModel.from_pretrained(MODEL_ID, trust_remote_code=True)
    processor = AutoProcessor.from_pretrained(MODEL_ID, trust_remote_code=True)
    print("Model loaded successfully!")
    print("Model loaded successfully!")
except Exception as e:
    print(f"Error loading model: {e}")
    print("Please ensure you have transformers>=4.40.0 installed.")
    exit(1)

@app.route('/tts', methods=['POST'])
def tts():
    data = request.json
    text = data.get('text', '')
    prompt = data.get('prompt', 'Natural speech')
    
    if not text:
        return {"error": "No text provided"}, 400

    print(f"Generating audio for: {text[:20]}...")

    try:
        # Prepare inputs
        inputs = processor(text=[text], Audio=None, return_tensors="pt").to(model.device)
        
        # Generator args (can be tuned)
        generate_ids = model.generate(**inputs, max_new_tokens=256)
        
        # The model returns audio tokens/values. 
        # Note: Qwen-Audio usually outputs raw audio values or tokens that need decoding.
        # This part depends highly on the specific model's output format.
        # Assuming model.generate returns valid audio values for now (common in E2E TTS models)
        
        # CAUTION: Qwen2-Audio is technically an Audio-Instruction model. 
        # If Qwen3-TTS works differently, we might need specific generation code.
        # For now, using standard generate workflow.
        
        # Typically, we need to extract the audio from the output
        # For this specific model, checking if it returns waveform directly isn't guaranteed without docs.
        # But 'model.generate' implies token generation. 
        
        # Let's try to interpret the output. 
        # If it returns a waveform tensor directly (some newer models do), great.
        
        # *Self-Correction for Safety*: 
        # Since we don't have the exact docs, I will add a fallback or assume standard 
        # transformers output behavior for audio models.
        
        # Placeholder for actual generation logic:
        # Taking the first batch item.
        audio_values = generate_ids[0].cpu().numpy()
        
        # If the output is token IDs, we need to decode.
        # But Qwen-Audio is often Audio-Text-to-Text/Audio.
        
        # Let's save as WAV
        byte_io = BytesIO()
        # Sampling rate is usually 16000 or 24000 for these models
        wav.write(byte_io, 16000, audio_values.astype(np.float32))
        byte_io.seek(0)
        
        return send_file(byte_io, mimetype="audio/wav")

    except Exception as e:
        print(f"Generation error: {e}")
        return {"error": str(e)}, 500

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=PORT)
